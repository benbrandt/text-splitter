[package]
name = "text-splitter"
version = "0.6.0"
authors = ["Ben Brandt <benjamin.j.brandt@gmail.com>"]
edition = "2021"
description = "Split text into semantic chunks, up to a desired chunk size. Supports calculating length by characters and tokens (when used with large language models)."
repository = "https://github.com/benbrandt/text-splitter"
license = "MIT"
keywords = ["text", "split", "tokenizer", "nlp", "ai"]
categories = ["text-processing"]
exclude = ["/tests/snapshots/**", "/tests/inputs/**", "/bindings/**"]
rust-version = "1.65.0"

[package.metadata.docs.rs]
all-features = true
rustdoc-args = ["--cfg", "docsrs"]

# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

[dependencies]
auto_enums = "0.8.3"
either = "1.9.0"
itertools = "0.12.0"
once_cell = "1.18.0"
regex = "1.10.2"
tiktoken-rs = { version = "0.5.6", optional = true }
tokenizers = { version = "0.15.0", default_features = false, features = ["onig"], optional = true }
unicode-segmentation = "1.10.1"

[dev-dependencies]
criterion = "0.5.1"
fake = "2.9.1"
insta = { version = "1.34.0", features = ["glob", "yaml"] }
more-asserts = "0.3.1"
tokenizers = { version = "0.15.0", default-features = false, features = [
    "onig",
    "http",
] }

[[bench]]
name = "chunk_size"
harness = false

[features]
tokenizers = ["dep:tokenizers"]
tiktoken-rs = ["dep:tiktoken-rs"]

# Tokenizers and indirect deps can cause slow runtime
[profile.dev.package."*"]
opt-level = 1

[profile.dev.package.insta]
opt-level = 3

[profile.dev.package.similar]
opt-level = 3
